\chapter{Open Questions and Further Research}\label{ch:closing}

\vspace*{-50pt}

\begin{figure}[ht]
        \includegraphics[width=0.35\textwidth, right]{img/further-questions.png}
        \captionsetup{textformat=empty,labelformat=blank}
        \caption[Generated with Dalle-E. Knowledge Cutoff 09-2022]{Generated with Dall-E. \url{https://labs.openai.com/}. ``more ducks asking further questions and research topics''}
\end{figure}

\epigraph{\itshape ``Peter does what he usually does when he doesnâ€™t know what to do next: he gives up.''}{Qualityland, \textit{Marc-Uwe Kling}}

Now that all ducks are happy again, you still have some questions in mind.
After you have shown a linear kernel of size $\kernelsize \cdot k$ and, when parameterized by the solution size, that it does probably not exist for \textit{split graphs} and \textit{bipartite} graphs - including \textit{triangle-free} and \textit{chordal} graphs - you still have some open questions worth to be investigated.


\noindent \textbf{Improving Kernel~}
The constant of the kernel size $\kernelsize \cdot k$ is very high and the usage of an exponential time algorithm yields a total running time of  $\mathcal{O}(2^{\kernelsize k} \cdot poly(n))$, which is too large for practical applications.
It would be interesting to improve them and one idea would be the following:
\cref{rgl:rtwo} uses the fact that $N(v,w)$ can be dominated by at most four vertices: $v$, $w$ and two neighbors as a witness.
Observe that if $d(v,w) \leq 3$, this witness might be shared in an sds, because choosing one single witness on the path from $v$ to $w$ is sufficient to semitotally dominate $N(v,w)$.
Therefore $\Dvw$, $\Dv$ and $\Dw$ could be redefined to contain sets of size at most two (instead of three) which will improve the reduction. 
Note that in our analysis, the poles of a region $R$ in the \dreg $\mathfrak{R}$ satisfy $d(v,w) \leq 3$ by definition.
Therefore, requiring $d(v,w) \leq 3$ would be ok and we can still assume that \cref{rgl:rtwo} has been applied for any $R \in \mathfrak{R}$.
$d(v,w)$ can be calculated in linear time and would not blow up our runtime.

\noindent \textbf{Experimental Results~}
Our bound and its large constants refer to the worst-case scenario which tells us little about the performance applied to real-world instances.
Already Alber et al.~\cite{Alber2004} noticed that these kinds of reduction rules behave very well in nature and showed in an experimental setting for \pdom that on average more than $79\%$ of the vertices and $88\%$ of the edges have been removed by their reduction rules from a sample set of random planar graphs with up to $4000$ vertices. 
As our reduction rules differ from those given in \cite{Alber2004}, it would be interesting to see, how much random graphs are reduced using our preprocessing algorithm. \cref{rgl:rone,rgl:rtwo,rgl:rthree}.

\noindent \textbf{Other Open Problems~}
The classical complexities for \textit{dually chordal} and \textit{tolerance} graphs have already been asked for by Galby et al.~\cite{Galby2020} and are still open.
Furthermore, it would be interesting to complement the parameterized complexities on the hard classes we have started in this work.
open are those for \textit{circle}, \textit{chordal bipartite} and \textit{undirected path} graphs.
We think that \sdoms on \textit{chordal bipartite} graphs is at least \WONEhs-hard when parameterized by solution size, but we have been unable to prove it.
Furthermore, the reduction for \textit{circle} graphs~\cite{Kloks2021} to show \NP-completeness depends on the input size, but \doms and \tdoms have already been shown to be \WONEhs-hard on \textit{circle} graphs~\cite{Bousquet2012}. 
Maybe these reductions can be adjusted to show \WONEhs-hardness for \sdoms as well.
Last but not least, there exists an fpt algorithm for \doms on \textit{undirected path} graphs~\cite{Figueiredo2022}. 
Does it transfer to \sdoms as well?