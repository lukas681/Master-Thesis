\section{Computational Complexity Theory}

Computational complexity investigates how many computational resources are required to solve a specific problem. 
We are about to introduce two of the most important classes of problems in classical complexity theory:

\begin{cc}[The Classes \Pt and \NP茔轸妍硫矧岵鞍洱蓰沣吼铕涉麇溴铒翦苣陨团狍翳箦镦溴汩箝镱痱镡戾眢翳狒狎箫祧徕戾轭ぼ磲翳汜禧淆钷氅糸礤怡溴翦蝽轭轶糸怎蜷铉歪汨轭瀣麇汜溴骈铄翳沆狍苄狍苒茼狒栩睇旋航茆殓沲疬荛茼狒桠恹锡ㄜ磲翳蝽脑赏琵钷氅┸茴镩钿孱灬铉踽珏ぬ荏踱箦翦茺艾避蕺轶轭芪殒翳弪屮轶趔痫禊铒黹犰ゐ茼狒桠恹锡茯殓梏狎蝻茼狒桠恹锡犷痫禊铒黹犰糸礤怎蜷铉歪汨轭ね篚汨翳狒骘弼弪荛茺艾避蕺が苒荛芴彐趄殓梏狎蝻苠轶趔荛茺艾避摞皎茼狒桀矧磲禧螽舢 M(x,u) = 1 \]

    \noindent If $x \in L$ and $u \in \{ 0,1 \}^{p(|x|)}$ satisfy $M(x,u) = 1$, then we call $u$  a \textit{certificate} for $x$.

\end{cc}

\Pt denotes the class of all problems that are \textit{efficiently solvable}, whereas \NP contains all problems whose solution can efficiently be verified. Note that $\Pt \subseteq \NP$, but the opposite is unknown.
\subsection{\NPcn}\label{ch:npc}
A significant discovery in the early 1970s was that some problems in \NP are \textit{at least as hard as} as any other problem in \NP. By spanning a whole ``web of reductions'' \cite{Arora2006} we get strong evidence that none of these problems can be solved efficiently.
The first results in this new field were published independently by Cook \cite{Cook1971} and Levin \cite{Levin1973} after Karp \cite{Karp1972} had introduced the notion of problem reductions.
The Cook-Levin-Theorem \cite{Cook1971} proved that the \SAT (\SATs) problem is \NPc any problem in $NP$ can be reduced to \SATs. 
A single algorithm for one of these problems \NPc problems would instantly give a fast algorithm for the others as well. 
We refer the reader to \cite{Arora2006} for a comprehensive introduction to classical complexity theory.

\begin{definition}[{Reductions, \NP-hardness and \NPcn \cite{Arora2006}}]
We say that a language $A\subseteq \{0,1\}^*$ is \textit{polynomial-time karp reducible} to a language $B \subseteq \{0,1\}^*$ (denote $A \leq_p B$) if there is a poly-time computable function $f: \{0,1\}^* \rightarrow \{0,1\}^*$ such that for every $x \in \{0,1\}^*$, $x \in A$ if and only if $f(x) \in B$.

\noindent We say that a problem $B$ is \NPh if $A \leq_p B$ for every $A \in \NP$ and $B$ is \NPc if additionally $B \in NP$ holds.

\end{definition}
There are thousands of \NPc problems we do not expect to be solvable in polynomial time.
Whether $\Pt \overset{?}{=} \NP$ is still one of the biggest open questions in mathematics and bountied with one million dollars by the \textit{Clay Mathematical Institute} \cite{Fortnow2021}. 
Most of the domination problems like \dom, \sdom, \tdom are \NPc.

% \paragraph{Coping With \NPcn}

We do not expect \NPc problems to have a polynomial-time algorithm, but strategies exist to cope with them. 
We can either give up the exactness of a solution to possibly find fast \textit{approximation algorithms} or abandon the search for a polynomial-time algorithm in favor of finding good \textit{Exact Exponential (EEA) Algorithms} instead.
A third technique is using additional structural parameters of a specific problem instance and therefore \textbf{restricting the input to special cases}. 
This idea led to the development of \textit{parameterized complexity}.

\section{Parameterized Complexity}\label{cha:param}

Introduced by Downey and Fellows \cite{Downey1999a}, parameterized complexity extends the classical theory with a framework that allows a more dimensional analysis of computationally hard problems. 
The idea is to extract an arbitrary parameter $k$ and find an algorithm that is only exponential in a function $f(k)$ but only polynomial in the instance size.
$k$ denotes how complex the problem is: 
$k$ can be seen as a measure of the difficulty of a given instance.
If $k$ is small, the problem can still be considered tractable, although the underlying \NPh problem is generally intractable.
All definitions are taken from \cite{Cygan2015} if not marked otherwise.

\begin{definition}[Parameterized Problem]
    A parameterized problem is a language $L\subseteq\Sigma^*\times \mathbb{N}$ where $\Sigma$ is a finite, fixed alphabet.
    For an instance $(x,k) \in \Sigma^*\times \mathbb{N}$, $k$ is called the \textit{parameter}.

    The \underline{size of an instance} of an instance $(x,k)$ of a parameterized problem is $\abs{(x,k)} = \abs{x} + k$ where the parameter $k$ is encoded in unary by convention.
\end{definition}

\subsection{Fixed-Parameter Tractability}
We say that a problem is \textit{fixed-parameter tractable (fpt)} if problem instances of size $n$ can be solved in $f(k)n^{\mathcal{O}(1)}$ time for some function $f$ independent of $n$. 
Like the class \Pt can be seen as a notion of \textit{tractability} in classical complexity theory, there is an equivalent in parameterized complexity, which we denote as \FPTl (\FPT):

\begin{cc} [The Class \FPT]{cc:fpt}
    A parameterized problem $L\subseteq\Sigma^*\times\mathbb{N}$ is called \textit{fixed-parameter tractable} if there exists an algorithm A (called a \textit{fixed-parameter algorithm}), a computable function $f:\mathbb{N} \rightarrow \mathbb{N}$ and a constant c such that, given $(x,k) \in \Sigma^* \times \mathbb{N}$, the algorithm $\mathcal{A}$ correctly decides whether $(x,k) \in L$ in time bounded by $f(k) \cdot |(x,k)|^c$. The complexity class containing all fixed-parameter tractable problems is called \FPT.
\end{cc}
\subsection{Kernelization}

A kernelization algorithm is a natural and intuitive way to approach problems and is a preprocessing procedure that simplifies parts of an instance before the actual solving algorithm runs. 
The \cref{fig:kernelization} visualizes this idea.
One can introduce different \textit{reduction rules} that iteratively reduce the instance until we are left with a small kernel. 
Ideally, the size of this kernel is merely dependent on the parameter $k$.

\begin{definition}[Kernelization and Reduction Rules]
A \textit{kernelization algorithm} or \textit{kernel} is an algorithm $\mathfrak{A}$ for a parameterized problem $Q$ that given an instance $(I,k)$ of $Q$ runs in polynomial time and returns an equivalent instance $(I', k')$ of $Q$. 
Moreover, we require that $size_{\mathfrak{A}}(k) \leq g(k)$ for some computable function $g:\mathbb{N} \rightarrow \mathbb{N}$.

A \underline{reduction rule} is a function $\phi:\Sigma^* \times \mathbb{N} \rightarrow \Sigma^* \times \mathbb{N}$ that maps an instance $(x,k)$ to an equivalent instance $(x',k')$ such that $\phi$ is computable in time polynomial in $\abs{x}$ and $k$.
A reduction rule is \underline{sound} (or \underline{safe}) if $(I, k) \in Q \Leftrightarrow (I',k') \in Q$.
\end{definition}

We can precisely define the kernel's size after executing a preprocessing algorithm $\mathfrak{A}$.

\begin{definition}[Output Size of a Preprocessing Algorithm] The output size of a preprocessing algorithms $\mathfrak{A}$ is defined as 

    \[\mathrm{size}_{\mathfrak{A}}(k) = \sup\{\abs{I'} + k': (I',k')= \mathfrak{A}(I,k), I \in \Sigma^* \} \]
\end{definition}


$size_{\mathfrak{A}}$ denotes the largest size of any instance $I$ after $\mathfrak{A}$ has been applied.
If no function merely dependent on $k$ can bound it, we consider it to be \emph{infinite}.
If we bound $\mathrm{size}_{\mathfrak{A}}$ by a polynomial in $k$, we say that the problem admits a \textbf{polynomial kernel} or a \textbf{linear} kernel analogously.

\begin{figure}
    \centering
    \input{fig/mathcha/kernelization.tikz}
    \caption[Idea of kernelization]{\textit{The Idea of Kernelization: Reducing an instance $(I,k) \in Q$ of size $n$ to a smaller instance $(I', k') \in Q$ in polynomial time. 
    The resulting size of the kernel is a function $g(k)$ only dependent on $k$.}
    }
    \label{fig:kernelization}
\end{figure}
The following \cref{lemma:fptiskernel} shows the relation between the complexity class \FPT and a kernelization algorithm. 
If we find a kernelization algorithm $\mathfrak{A}$ for a (decidable) problem $P$, we immediately obtain an fpt algorithm.
First, we will run $\mathfrak{A}$ on the given instance in polynomial time and then solve the kernel with an exponential time algorithm.
The total running time is of order $\mathcal{O}(g(f(k)) \cdot \mathrm{poly}(n))$ and hence, fpt.
Surprisingly, also the converse is true:

\begin{lemma}\label{lemma:fptiskernel}
    A parameterized problem $Q$ is \FPT if and only if it admits a kernelization algorithm.
\end{lemma}

 We will use this property in \cref{ch:linkern} to construct a kernel for \psdom and showing membership in \FPT.

\subsection{Reductions and Parameterized Intractability}

It is natural to ask whether all (hard) problems are also fixed-parameter tractable.
The answer is no, and parameterized complexity has another tool to show that a problem is unlikely to be in \FPT.
The idea is to transfer the concepts of \NP-hardness from \Cref{ch:npc} and reductions from the classical setting to the parameterized world.
This raises the need for a new type of reduction that ensures that a reduced instance $(I', k')$ is not only created in fpt time, but the new parameter $k'$ depends only on the size of the parameter in the original instance.

There exists a whole hierarchy of classes $\FPT \subseteq \WONE \subseteq \WTWO \subseteq ... \subseteq \Wt \subseteq ...$, which is known as the \WHIERARCHY.
It is strongly believed that $\FPT \subsetneq \Wt$ and therefore, we do not expect the existence of an algorithm solving any \Wt-hard problem in fpt time.

\begin{definition}[Parameterized Reduction] Let $A,B\subseteq \Sigma^*\times\mathbb{N}$ two parameterized problems. A \textit{parameter preserving reduction} from $A$ to $B$ is an algorithm that, given an instance $(x,k)$ of $A$, outputs an instance $(x', k')$ of $B$ such that:
    \begin{itemize}
        \item $(x,k)$ is a \textcolor{darkgray}{\textbf{yes instance}} of A \textbf{iff} $(x',k')$ is a \textcolor{darkgray}{\textbf{yes instance}} of B,
        \item $k' \leq g(k)$ for some computable function $g$, and
        \item runs in fpt-time $f(k)\cdot |x|^{\mathcal{O}(1)}$ for some computable function f.
    \end{itemize}
\end{definition}

\cref{lem:cfptr,lem:trans} shwon in \cite{Cygan2015} show this definition ensures that reductions are transitive and closed under fpt reductions.

\begin{lemma}[Closed Under fpt-reductions]\label{lem:cfptr}
    If there is a parameterized reduction from $A$ to $B$ and $B \in \FPT$, then $A \in \FPT$.
\end{lemma}

\begin{lemma}[Transitivity] \label{lem:trans}
    If there are parameterized reductions from $A$ to $B$ and from $B$ to $C$, then there is a parameterized reduction from $A$ to $C$.
\end{lemma}

If there exists a parameterized reduction transforming a \Wt-hard problem $A$ to another problem $B$, then $B$ is \Wt-hard as well.
We can define the classes \WONE and \WTWO by giving two problems that are complete for these classes.

\begin{cc}[The Classes \WONE 茔轸妍娘黝妁惫沟犷茏宰茔轸妍鸣玑畈氨谍蓰沣瑚辇茆彗轭犰殓瞠苘郗插磔苘郗冲磔荇屮酐荛轶荇屮酐茏衔怒泔眇戾翦苘荇屮酐茕镯轶荇屮酐茏宰檄泔眇戾翦苠钿犰殓瞠痱镡戾ば轶轭翳沆狍茏衔蝈箴茏宰烯殒翳弪轶疳蜥礤翦蜷邃蝈漉泗轱骝镯ば麸荛ㄜ滹愆苠钿沣盹蝈痱镦秕钿轭趄镤蹉糸镱轶铒蝈聃轵邃骘翳轶黠螂犷麇蝈驽翳轭翦蝈篝邃蝈徜弪麸茔轸妍鸣玑畈氨惮骑黹畈氨过骘盹蝈溴翎殪螽